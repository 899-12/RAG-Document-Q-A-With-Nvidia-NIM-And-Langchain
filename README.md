# RAG-Document-Q-A-With-Nvidia-NIM-And-Langchain
# NVIDIA NIM Demo

This application demonstrates a retrieval-based question-answering system using NVIDIA's NIM APIs. It leverages document embeddings, FAISS for vector search, and NVIDIA LLMs for generating responses. Below is an overview of how to set up and run the application.

---

## Requirements

### Libraries
The following Python libraries are required:

- **Streamlit**: For building the interactive user interface
- **LangChain**: For working with document loaders, text splitters, and retrieval chains
- **FAISS**: For building and querying the vector store
- **dotenv**: For managing environment variables securely
- **os**: For handling file and environment operations
- **time**: For measuring response times

### API Key
- NVIDIA API key is required for accessing NVIDIA NIM endpoints.
- Store the API key in a `.env` file as follows:

```env
NVIDIA_API_KEY=your_api_key_here
```

---

## Directory Structure
Ensure the following directory structure exists:

```
project-directory/
|
|-- us_census/                # Directory containing PDF files to be processed
|-- app.py                    # Main application script
|-- .env                      # Environment file with the NVIDIA API key
```

---

## Code Overview

### Key Components

#### **1. Document Loading and Processing**
- The code uses `PyPDFDirectoryLoader` to load PDFs from the `us_census` directory.
- Documents are chunked into smaller pieces using `RecursiveCharacterTextSplitter`.

#### **2. Vector Store**
- FAISS is used to create a vector store from the document embeddings generated by NVIDIA's embedding model.
- The vector store is saved in the Streamlit session state for efficient querying.

#### **3. Question Answering**
- A user inputs a question through the Streamlit interface.
- The system retrieves relevant document chunks from the vector store and generates an accurate response using NVIDIA's LLM.

### Functions and Features

#### `vector_embedding()`
- Loads and processes documents to create a vector store with embeddings from NVIDIA's API.
- Stores the vector store in `st.session_state`.

#### User Interface
- **Text Input**: Users can enter a question.
- **Buttons**: A button to embed documents and prepare the vector store.
- **Expandable Section**: Displays document chunks that are most relevant to the query.

---

## How to Run

1. **Install Required Libraries**:
   Install the dependencies using pip:

   ```bash
   pip install streamlit langchain faiss-cpu python-dotenv
   ```

2. **Set Up Environment Variables**:
   Create a `.env` file in the project directory and add your NVIDIA API key.

3. **Prepare Data**:
   Place your PDF documents in the `us_census` directory.

4. **Run the Application**:
   Start the Streamlit app with the following command:

   ```bash
   streamlit run app.py
   ```

5. **Use the Application**:
   - Click the **"Documents Embedding"** button to process and store document embeddings.
   - Enter a query in the text input field and view the answer along with relevant document chunks.

---

## Output

- **Response Time**: The system prints the time taken to generate the response.
- **Document Similarity Search**: Displays chunks of documents most relevant to the input question.

---

## Notes

- Ensure your `.env` file is secure and never commit it to version control.
- This code currently processes only the first 30 documents for embeddings. Adjust the slicing as needed.
- For optimal performance, ensure your system meets the hardware requirements for NVIDIA's APIs.

---

## Future Improvements

- Add error handling for missing API keys and invalid inputs.
- Implement support for additional document formats.
- Optimize document chunking for more efficient retrieval.
- Enhance the user interface with additional features like document upload or real-time feedback.


